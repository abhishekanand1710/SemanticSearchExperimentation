{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:04:37.308212Z","iopub.execute_input":"2023-05-01T19:04:37.308787Z","iopub.status.idle":"2023-05-01T19:04:50.300301Z","shell.execute_reply.started":"2023-05-01T19:04:37.308716Z","shell.execute_reply":"2023-05-01T19:04:50.298951Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.27.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.13.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence_transformers) (0.13.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.11.4)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence_transformers) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers) (1.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence_transformers) (9.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\nBuilding wheels for collected packages: sentence_transformers\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=f0eb4b9c5dec066ff8714971162b862ed88f5ef0b79d0db08cf8198c9afb3f1e\n  Stored in directory: /root/.cache/pip/wheels/83/71/2b/40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\nSuccessfully built sentence_transformers\nInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom string import digits\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nimport re\nfrom tqdm import tqdm, notebook\n\nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-01T19:04:50.302749Z","iopub.execute_input":"2023-05-01T19:04:50.303081Z","iopub.status.idle":"2023-05-01T19:04:54.402775Z","shell.execute_reply.started":"2023-05-01T19:04:50.303047Z","shell.execute_reply":"2023-05-01T19:04:54.401506Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n/kaggle/input/arxiv-cs-papers-abstract-from-2010/cs_arxiv_from_2010.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"docs_df = pd.read_csv('/kaggle/input/arxiv-cs-papers-abstract-from-2010/cs_arxiv_from_2010.csv')\ndocs_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:04:54.404329Z","iopub.execute_input":"2023-05-01T19:04:54.404894Z","iopub.status.idle":"2023-05-01T19:05:08.085699Z","shell.execute_reply.started":"2023-05-01T19:04:54.404863Z","shell.execute_reply":"2023-05-01T19:05:08.084482Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"         id                                            authors  \\\n0  704.0213              Ketan D. Mulmuley Hariharan Narayanan   \n1  704.1409                                      Yao HengShuai   \n2  704.1829  Stefan Felsner, Kamil Kloch, Grzegorz Matecki,...   \n3  705.0561                                     Jing-Chao Chen   \n4  705.1025                                     David Eppstein   \n\n                                               title            category  \\\n0  Geometric Complexity Theory V: On deciding non...           ['cs.CC']   \n1        Preconditioned Temporal Difference Learning  ['cs.LG', 'cs.AI']   \n2  On-line Chain Partitions of Up-growing Semi-or...           ['cs.DM']   \n3  Iterative Rounding for the Closest String Problem  ['cs.DS', 'cs.CC']   \n4        Recognizing Partial Cubes in Quadratic Time           ['cs.DS']   \n\n                                            abstract  \n0    This article has been withdrawn because it h...  \n1    This paper has been withdrawn by the author....  \n2    On-line chain partition is a two-player game...  \n3    The closest string problem is an NP-hard pro...  \n4    We show how to test whether a graph with n v...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>authors</th>\n      <th>title</th>\n      <th>category</th>\n      <th>abstract</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>704.0213</td>\n      <td>Ketan D. Mulmuley Hariharan Narayanan</td>\n      <td>Geometric Complexity Theory V: On deciding non...</td>\n      <td>['cs.CC']</td>\n      <td>This article has been withdrawn because it h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>704.1409</td>\n      <td>Yao HengShuai</td>\n      <td>Preconditioned Temporal Difference Learning</td>\n      <td>['cs.LG', 'cs.AI']</td>\n      <td>This paper has been withdrawn by the author....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>704.1829</td>\n      <td>Stefan Felsner, Kamil Kloch, Grzegorz Matecki,...</td>\n      <td>On-line Chain Partitions of Up-growing Semi-or...</td>\n      <td>['cs.DM']</td>\n      <td>On-line chain partition is a two-player game...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>705.0561</td>\n      <td>Jing-Chao Chen</td>\n      <td>Iterative Rounding for the Closest String Problem</td>\n      <td>['cs.DS', 'cs.CC']</td>\n      <td>The closest string problem is an NP-hard pro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>705.1025</td>\n      <td>David Eppstein</td>\n      <td>Recognizing Partial Cubes in Quadratic Time</td>\n      <td>['cs.DS']</td>\n      <td>We show how to test whether a graph with n v...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"device = 'cuda'\nif torch.cuda.is_available():      \n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:08.089902Z","iopub.execute_input":"2023-05-01T19:05:08.090711Z","iopub.status.idle":"2023-05-01T19:05:08.167363Z","shell.execute_reply.started":"2023-05-01T19:05:08.090656Z","shell.execute_reply":"2023-05-01T19:05:08.166345Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"docs_text = (docs_df['title'] + ' ' + docs_df['abstract']).values.tolist()\ndocs_text[:5]","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:08.168777Z","iopub.execute_input":"2023-05-01T19:05:08.169188Z","iopub.status.idle":"2023-05-01T19:05:08.784955Z","shell.execute_reply.started":"2023-05-01T19:05:08.169135Z","shell.execute_reply":"2023-05-01T19:05:08.783826Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[\"Geometric Complexity Theory V: On deciding nonvanishing of a generalized\\n  Littlewood-Richardson coefficient   This article has been withdrawn because it has been merged with the earlier\\narticle GCT3 (arXiv: CS/0501076 [cs.CC]) in the series. The merged article is\\nnow available as:\\n  Geometric Complexity Theory III: on deciding nonvanishing of a\\nLittlewood-Richardson Coefficient, Journal of Algebraic Combinatorics, vol. 36,\\nissue 1, 2012, pp. 103-110. (Authors: Ketan Mulmuley, Hari Narayanan and Milind\\nSohoni)\\n  The new article in this GCT5 slot in the series is:\\n  Geometric Complexity Theory V: Equivalence between blackbox derandomization\\nof polynomial identity testing and derandomization of Noether's Normalization\\nLemma, in the Proceedings of FOCS 2012 (abstract), arXiv:1209.5993 [cs.CC]\\n(full version) (Author: Ketan Mulmuley)\\n\",\n 'Preconditioned Temporal Difference Learning   This paper has been withdrawn by the author. This draft is withdrawn for its\\npoor quality in english, unfortunately produced by the author when he was just\\nstarting his science route. Look at the ICML version instead:\\nhttp://icml2008.cs.helsinki.fi/papers/111.pdf\\n',\n 'On-line Chain Partitions of Up-growing Semi-orders   On-line chain partition is a two-player game between Spoiler and Algorithm.\\nSpoiler presents a partially ordered set, point by point. Algorithm assigns\\nincoming points (immediately and irrevocably) to the chains which constitute a\\nchain partition of the order. The value of the game for orders of width $w$ is\\na minimum number $\\\\fVal(w)$ such that Algorithm has a strategy using at most\\n$\\\\fVal(w)$ chains on orders of width at most $w$. We analyze the chain\\npartition game for up-growing semi-orders. Surprisingly, the golden ratio comes\\ninto play and the value of the game is $\\\\lfloor\\\\frac{1+\\\\sqrt{5}}{2}\\\\; w\\n\\\\rfloor$.\\n',\n 'Iterative Rounding for the Closest String Problem   The closest string problem is an NP-hard problem, whose task is to find a\\nstring that minimizes maximum Hamming distance to a given set of strings. This\\ncan be reduced to an integer program (IP). However, to date, there exists no\\nknown polynomial-time algorithm for IP. In 2004, Meneses et al. introduced a\\nbranch-and-bound (B & B) method for solving the IP problem. Their algorithm is\\nnot always efficient and has the exponential time complexity. In the paper, we\\nattempt to solve efficiently the IP problem by a greedy iterative rounding\\ntechnique. The proposed algorithm is polynomial time and much faster than the\\nexisting B & B IP for the CSP. If the number of strings is limited to 3, the\\nalgorithm is provably at most 1 away from the optimum. The empirical results\\nshow that in many cases we can find an exact solution. Even though we fail to\\nfind an exact solution, the solution found is very close to exact solution.\\n',\n 'Recognizing Partial Cubes in Quadratic Time   We show how to test whether a graph with n vertices and m edges is a partial\\ncube, and if so how to find a distance-preserving embedding of the graph into a\\nhypercube, in the near-optimal time bound O(n^2), improving previous O(nm)-time\\nsolutions.\\n']"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(text, remove_stopwords=True):\n    text = text.lower()\n    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n    text = re.sub(r'\\<a href', ' ', text)\n    text = re.sub(r'&amp;', '', text) \n    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n    text = re.sub(r'<br />', ' ', text)\n    text = re.sub(r'\\'', ' ', text)\n    \n    if remove_stopwords:\n        text = text.split()\n        stops = set(stopwords.words('english'))\n        text = [w for w in text if w not in stops]\n        text = ' '.join(text)\n        \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:08.786672Z","iopub.execute_input":"2023-05-01T19:05:08.787804Z","iopub.status.idle":"2023-05-01T19:05:08.795925Z","shell.execute_reply.started":"2023-05-01T19:05:08.787755Z","shell.execute_reply":"2023-05-01T19:05:08.794538Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def clean_data(data):\n    cleaned_data = []\n    for doc in notebook.tqdm(data):\n        text = clean_text(doc, False)\n        cleaned_data.append(text)\n    return cleaned_data","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:08.797607Z","iopub.execute_input":"2023-05-01T19:05:08.798383Z","iopub.status.idle":"2023-05-01T19:05:08.806993Z","shell.execute_reply.started":"2023-05-01T19:05:08.798352Z","shell.execute_reply":"2023-05-01T19:05:08.805846Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"cleaned_docs = clean_data(docs_text)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:08.808436Z","iopub.execute_input":"2023-05-01T19:05:08.809510Z","iopub.status.idle":"2023-05-01T19:05:20.842542Z","shell.execute_reply.started":"2023-05-01T19:05:08.809378Z","shell.execute_reply":"2023-05-01T19:05:20.841476Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/484027 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f0d1b8d73ec44d0ac738d48f38929b7"}},"metadata":{}}]},{"cell_type":"code","source":"embedder = SentenceTransformer('all-MiniLM-L6-v2', device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:20.844221Z","iopub.execute_input":"2023-05-01T19:05:20.844896Z","iopub.status.idle":"2023-05-01T19:05:27.966537Z","shell.execute_reply.started":"2023-05-01T19:05:20.844857Z","shell.execute_reply":"2023-05-01T19:05:27.965381Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f91ea4b96ac4b098d46376efb11ebcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"206c189d97ff4919a27cc156ab3f4080"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3211c13ac89547b3a3f8c36e43fb0f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aca281e08d2947c6823bdc3fa4270679"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ae0c69bf0bf4fd9884f1b7376b73bb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28ef78aaab874c70a5d23003c873e618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cddd48bef24073975e8c9c667895d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a007c2803984cc4ba4c12e3b96bdbf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67b95f8560b3461da25903f0fe0e4ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f7af64f481a41eabc5541a4fa97201d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e856e97d0745af9e59b2114395c0a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0702f26bb2db482486215e0949d1c88f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89665641e1d54a5db1622ae4a990bf82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaec10d9ec4a470eafe0be3aaeda55d9"}},"metadata":{}}]},{"cell_type":"code","source":"def get_embeddings(data):\n    return embedder.encode(data, convert_to_tensor=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:27.971612Z","iopub.execute_input":"2023-05-01T19:05:27.971925Z","iopub.status.idle":"2023-05-01T19:05:27.977390Z","shell.execute_reply.started":"2023-05-01T19:05:27.971895Z","shell.execute_reply":"2023-05-01T19:05:27.976161Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"abstract_embeddings = get_embeddings(cleaned_docs)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:05:27.978959Z","iopub.execute_input":"2023-05-01T19:05:27.979638Z","iopub.status.idle":"2023-05-01T19:16:54.079221Z","shell.execute_reply.started":"2023-05-01T19:05:27.979599Z","shell.execute_reply":"2023-05-01T19:16:54.078124Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/15126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aeabb69a20d452781dfe269282afc4b"}},"metadata":{}}]},{"cell_type":"code","source":"query = ['temporal expression extraction']\nquery_embedding = get_embeddings(query)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.085235Z","iopub.execute_input":"2023-05-01T19:16:54.085618Z","iopub.status.idle":"2023-05-01T19:16:54.135585Z","shell.execute_reply.started":"2023-05-01T19:16:54.085587Z","shell.execute_reply":"2023-05-01T19:16:54.134490Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b558d5b9af94b22a34a52c35560c9c1"}},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\ncos_scores = util.cos_sim(query_embedding, abstract_embeddings)\ncos_scores.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.137129Z","iopub.execute_input":"2023-05-01T19:16:54.138053Z","iopub.status.idle":"2023-05-01T19:16:54.150005Z","shell.execute_reply.started":"2023-05-01T19:16:54.138015Z","shell.execute_reply":"2023-05-01T19:16:54.148785Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CPU times: user 2.27 ms, sys: 1.02 ms, total: 3.28 ms\nWall time: 3.32 ms\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 484027])"},"metadata":{}}]},{"cell_type":"code","source":"cos_scores[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.151514Z","iopub.execute_input":"2023-05-01T19:16:54.152178Z","iopub.status.idle":"2023-05-01T19:16:54.179200Z","shell.execute_reply.started":"2023-05-01T19:16:54.152140Z","shell.execute_reply":"2023-05-01T19:16:54.178159Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"tensor([ 0.0448,  0.3572,  0.0271,  ...,  0.1939, -0.0275,  0.0822],\n       device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"top_results = torch.topk(cos_scores[0], k=5)\ntop_results","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.180488Z","iopub.execute_input":"2023-05-01T19:16:54.181234Z","iopub.status.idle":"2023-05-01T19:16:54.197843Z","shell.execute_reply.started":"2023-05-01T19:16:54.181196Z","shell.execute_reply":"2023-05-01T19:16:54.196692Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.return_types.topk(\nvalues=tensor([0.7779, 0.6950, 0.6800, 0.6714, 0.6708], device='cuda:0'),\nindices=tensor([ 16069, 154036,  66896,  13600, 192765], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see the closest match","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[16069].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.199211Z","iopub.execute_input":"2023-05-01T19:16:54.199938Z","iopub.status.idle":"2023-05-01T19:16:54.207314Z","shell.execute_reply.started":"2023-05-01T19:16:54.199900Z","shell.execute_reply":"2023-05-01T19:16:54.206244Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'  Automatic annotation of temporal expressions is a research challenge of great\\ninterest in the field of information extraction. In this report, I describe a\\nnovel rule-based architecture, built on top of a pre-existing system, which is\\nable to normalise temporal expressions detected in English texts. Gold standard\\ntemporally-annotated resources are limited in size and this makes research\\ndifficult. The proposed system outperforms the state-of-the-art systems with\\nrespect to TempEval-2 Shared Task (value attribute) and achieves substantially\\nbetter results with respect to the pre-existing system on top of which it has\\nbeen developed. I will also introduce a new free corpus consisting of 2822\\nunique annotated temporal expressions. Both the corpus and the system are\\nfreely available on-line.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"docs_df.iloc[154036].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.208526Z","iopub.execute_input":"2023-05-01T19:16:54.209436Z","iopub.status.idle":"2023-05-01T19:16:54.217796Z","shell.execute_reply.started":"2023-05-01T19:16:54.209400Z","shell.execute_reply":"2023-05-01T19:16:54.216529Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'  The current leading paradigm for temporal information extraction from text\\nconsists of three phases: (1) recognition of events and temporal expressions,\\n(2) recognition of temporal relations among them, and (3) time-line\\nconstruction from the temporal relations. In contrast to the first two phases,\\nthe last phase, time-line construction, received little attention and is the\\nfocus of this work. In this paper, we propose a new method to construct a\\nlinear time-line from a set of (extracted) temporal relations. But more\\nimportantly, we propose a novel paradigm in which we directly predict start and\\nend-points for events from the text, constituting a time-line without going\\nthrough the intermediate step of prediction of temporal relations as in earlier\\nwork. Within this paradigm, we propose two models that predict in linear\\ncomplexity, and a new training loss using TimeML-style annotations, yielding\\npromising results.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"abstract_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.219338Z","iopub.execute_input":"2023-05-01T19:16:54.219981Z","iopub.status.idle":"2023-05-01T19:16:54.226987Z","shell.execute_reply.started":"2023-05-01T19:16:54.219944Z","shell.execute_reply":"2023-05-01T19:16:54.225850Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"torch.Size([484027, 384])"},"metadata":{}}]},{"cell_type":"code","source":"query_embedding.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.228888Z","iopub.execute_input":"2023-05-01T19:16:54.229550Z","iopub.status.idle":"2023-05-01T19:16:54.236486Z","shell.execute_reply.started":"2023-05-01T19:16:54.229514Z","shell.execute_reply":"2023-05-01T19:16:54.235388Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 384])"},"metadata":{}}]},{"cell_type":"markdown","source":"Experimenting with FAISS by facebook","metadata":{}},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:16:54.238071Z","iopub.execute_input":"2023-05-01T19:16:54.238836Z","iopub.status.idle":"2023-05-01T19:17:05.857897Z","shell.execute_reply.started":"2023-05-01T19:16:54.238800Z","shell.execute_reply":"2023-05-01T19:17:05.856518Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.7.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.7.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import faiss","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:25:06.820873Z","iopub.execute_input":"2023-05-01T19:25:06.821918Z","iopub.status.idle":"2023-05-01T19:25:06.827953Z","shell.execute_reply.started":"2023-05-01T19:25:06.821859Z","shell.execute_reply":"2023-05-01T19:25:06.826547Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"abstract_embeddings_np = abstract_embeddings.detach().cpu().numpy()\nquery_embedding_np = query_embedding.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:32:54.568191Z","iopub.execute_input":"2023-05-01T19:32:54.568898Z","iopub.status.idle":"2023-05-01T19:32:55.247941Z","shell.execute_reply.started":"2023-05-01T19:32:54.568859Z","shell.execute_reply":"2023-05-01T19:32:55.246825Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Data is less, a flat index can be used.","metadata":{}},{"cell_type":"code","source":"dim=384","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:33:12.768147Z","iopub.execute_input":"2023-05-01T19:33:12.768529Z","iopub.status.idle":"2023-05-01T19:33:12.774204Z","shell.execute_reply.started":"2023-05-01T19:33:12.768495Z","shell.execute_reply":"2023-05-01T19:33:12.772925Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"index = faiss.IndexFlatL2(dim)\nindex.add(abstract_embeddings_np)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:33:13.141573Z","iopub.execute_input":"2023-05-01T19:33:13.142264Z","iopub.status.idle":"2023-05-01T19:33:13.832808Z","shell.execute_reply.started":"2023-05-01T19:33:13.142224Z","shell.execute_reply":"2023-05-01T19:33:13.831673Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:10.253399Z","iopub.execute_input":"2023-05-01T19:51:10.253811Z","iopub.status.idle":"2023-05-01T19:51:10.302809Z","shell.execute_reply.started":"2023-05-01T19:51:10.253776Z","shell.execute_reply":"2023-05-01T19:51:10.301624Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"CPU times: user 43.3 ms, sys: 4 µs, total: 43.3 ms\nWall time: 41.5 ms\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 154036,  66896,  13600, 192765]])"},"metadata":{}}]},{"cell_type":"code","source":"dist","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:11.640120Z","iopub.execute_input":"2023-05-01T19:51:11.640825Z","iopub.status.idle":"2023-05-01T19:51:11.648579Z","shell.execute_reply.started":"2023-05-01T19:51:11.640786Z","shell.execute_reply":"2023-05-01T19:51:11.647342Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"array([[0.444108  , 0.6100239 , 0.6400416 , 0.65727806, 0.6584898 ]],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"tensor([ 16069, 154036,  66896,  13600, 192765], device='cuda:0')\nfaiss internally uses the same scoring metric hence returns the same top 5 results.","metadata":{}},{"cell_type":"code","source":"index.is_trained","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:15.323536Z","iopub.execute_input":"2023-05-01T19:51:15.324500Z","iopub.status.idle":"2023-05-01T19:51:15.331746Z","shell.execute_reply.started":"2023-05-01T19:51:15.324448Z","shell.execute_reply":"2023-05-01T19:51:15.330490Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"index.ntotal","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:15.479834Z","iopub.execute_input":"2023-05-01T19:51:15.481365Z","iopub.status.idle":"2023-05-01T19:51:15.488683Z","shell.execute_reply.started":"2023-05-01T19:51:15.481322Z","shell.execute_reply":"2023-05-01T19:51:15.487350Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"484027"},"metadata":{}}]},{"cell_type":"markdown","source":"Experimenting with different index which involves training as it wont be on a metric and we won't be using a flat index for this part.","metadata":{}},{"cell_type":"markdown","source":"Adding Partitioning to the Index. Similar to Elasticsearch partitioning on index concept.","metadata":{}},{"cell_type":"code","source":"nlist = 200  # how many cells\nquantizer = faiss.IndexFlatL2(dim)\nindex = faiss.IndexIVFFlat(quantizer, dim, nlist)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:16.403494Z","iopub.execute_input":"2023-05-01T19:51:16.403889Z","iopub.status.idle":"2023-05-01T19:51:16.410074Z","shell.execute_reply.started":"2023-05-01T19:51:16.403853Z","shell.execute_reply":"2023-05-01T19:51:16.408739Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"index.is_trained","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:16.576472Z","iopub.execute_input":"2023-05-01T19:51:16.576771Z","iopub.status.idle":"2023-05-01T19:51:16.585408Z","shell.execute_reply.started":"2023-05-01T19:51:16.576744Z","shell.execute_reply":"2023-05-01T19:51:16.584199Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nindex.train(abstract_embeddings_np)\nindex.is_trained","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:16.740973Z","iopub.execute_input":"2023-05-01T19:51:16.742157Z","iopub.status.idle":"2023-05-01T19:51:17.942049Z","shell.execute_reply.started":"2023-05-01T19:51:16.742118Z","shell.execute_reply":"2023-05-01T19:51:17.940790Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"CPU times: user 1.15 s, sys: 41 ms, total: 1.19 s\nWall time: 1.19 s\n","output_type":"stream"},{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"index.ntotal","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:17.944322Z","iopub.execute_input":"2023-05-01T19:51:17.945610Z","iopub.status.idle":"2023-05-01T19:51:17.953518Z","shell.execute_reply.started":"2023-05-01T19:51:17.945556Z","shell.execute_reply":"2023-05-01T19:51:17.952036Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nindex.add(abstract_embeddings_np)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:17.955116Z","iopub.execute_input":"2023-05-01T19:51:17.956173Z","iopub.status.idle":"2023-05-01T19:51:19.745046Z","shell.execute_reply.started":"2023-05-01T19:51:17.956125Z","shell.execute_reply":"2023-05-01T19:51:19.743776Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"CPU times: user 1.31 s, sys: 469 ms, total: 1.78 s\nWall time: 1.78 s\n","output_type":"stream"}]},{"cell_type":"code","source":"index.ntotal","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:19.748144Z","iopub.execute_input":"2023-05-01T19:51:19.748577Z","iopub.status.idle":"2023-05-01T19:51:19.756038Z","shell.execute_reply.started":"2023-05-01T19:51:19.748535Z","shell.execute_reply":"2023-05-01T19:51:19.754772Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"484027"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:19.757863Z","iopub.execute_input":"2023-05-01T19:51:19.758652Z","iopub.status.idle":"2023-05-01T19:51:19.769978Z","shell.execute_reply.started":"2023-05-01T19:51:19.758613Z","shell.execute_reply":"2023-05-01T19:51:19.768723Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"CPU times: user 0 ns, sys: 949 µs, total: 949 µs\nWall time: 599 µs\n","output_type":"stream"},{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 347324, 368076,  28773,  13593]])"},"metadata":{}}]},{"cell_type":"markdown","source":"basically the search is taking less than a ms compared to 73 ms in the previous search without partitioning but the results are less accurate. Let's see some of the examples","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[16069].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:20.167054Z","iopub.execute_input":"2023-05-01T19:51:20.167706Z","iopub.status.idle":"2023-05-01T19:51:20.176174Z","shell.execute_reply.started":"2023-05-01T19:51:20.167674Z","shell.execute_reply":"2023-05-01T19:51:20.173950Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"'  Automatic annotation of temporal expressions is a research challenge of great\\ninterest in the field of information extraction. In this report, I describe a\\nnovel rule-based architecture, built on top of a pre-existing system, which is\\nable to normalise temporal expressions detected in English texts. Gold standard\\ntemporally-annotated resources are limited in size and this makes research\\ndifficult. The proposed system outperforms the state-of-the-art systems with\\nrespect to TempEval-2 Shared Task (value attribute) and achieves substantially\\nbetter results with respect to the pre-existing system on top of which it has\\nbeen developed. I will also introduce a new free corpus consisting of 2822\\nunique annotated temporal expressions. Both the corpus and the system are\\nfreely available on-line.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"first one is still the same","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[347324].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:21.793188Z","iopub.execute_input":"2023-05-01T19:51:21.793565Z","iopub.status.idle":"2023-05-01T19:51:21.803660Z","shell.execute_reply.started":"2023-05-01T19:51:21.793530Z","shell.execute_reply":"2023-05-01T19:51:21.802358Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"'  The understanding of time expressions includes two sub-tasks: recognition and\\nnormalization. In recent years, significant progress has been made in the\\nrecognition of time expressions while research on normalization has lagged\\nbehind. Existing SOTA normalization methods highly rely on rules or grammars\\ndesigned by experts, which limits their performance on emerging corpora, such\\nas social media texts. In this paper, we model time expression normalization as\\na sequence of operations to construct the normalized temporal value, and we\\npresent a novel method called ARTime, which can automatically generate\\nnormalization rules from training data without expert interventions.\\nSpecifically, ARTime automatically captures possible operation sequences from\\nannotated data and generates normalization rules on time expressions with\\ncommon surface forms. The experimental results show that ARTime can\\nsignificantly surpass SOTA methods on the Tweets benchmark, and achieves\\ncompetitive results with existing expert-engineered rule methods on the\\nTempEval-3 benchmark.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can see the second abstract doesn't exactly match the query - temporal expression extraction but is close to it. While the previous result without partiotioing the second abstract was a very close match for the query.","metadata":{}},{"cell_type":"markdown","source":"Third result","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[368076].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:22.819377Z","iopub.execute_input":"2023-05-01T19:51:22.819989Z","iopub.status.idle":"2023-05-01T19:51:22.827036Z","shell.execute_reply.started":"2023-05-01T19:51:22.819951Z","shell.execute_reply":"2023-05-01T19:51:22.826036Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"'  Extracting temporal relations among events from unstructured text has\\nextensive applications, such as temporal reasoning and question answering.\\nWhile it is difficult, recent development of Neural-symbolic methods has shown\\npromising results on solving similar tasks. Current temporal relation\\nextraction methods usually suffer from limited expressivity and inconsistent\\nrelation inference. For example, in TimeML annotations, the concept of\\nintersection is absent. Additionally, current methods do not guarantee the\\nconsistency among the predicted annotations. In this work, we propose SMARTER,\\na neural semantic parser, to extract temporal information in text effectively.\\nSMARTER parses natural language to an executable logical form representation,\\nbased on a custom typed lambda calculus. In the training phase, dynamic\\nprogramming on denotations (DPD) technique is used to provide weak supervision\\non logical forms. In the inference phase, SMARTER generates a temporal relation\\ngraph by executing the logical form. As a result, our neural semantic parser\\nproduces logical forms capturing the temporal information of text precisely.\\nThe accurate logical form representations of an event given the context ensure\\nthe correctness of the extracted relations.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"We can imporve the search accuracy by increasing the nprobe value which increases the number of cells searched.","metadata":{}},{"cell_type":"code","source":"index.nprobe","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:23.259814Z","iopub.execute_input":"2023-05-01T19:51:23.260176Z","iopub.status.idle":"2023-05-01T19:51:23.270424Z","shell.execute_reply.started":"2023-05-01T19:51:23.260143Z","shell.execute_reply":"2023-05-01T19:51:23.269122Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"index.nprobe = 10\nindex.nprobe","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:23.859806Z","iopub.execute_input":"2023-05-01T19:51:23.860167Z","iopub.status.idle":"2023-05-01T19:51:23.869328Z","shell.execute_reply.started":"2023-05-01T19:51:23.860133Z","shell.execute_reply":"2023-05-01T19:51:23.868182Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:24.612557Z","iopub.execute_input":"2023-05-01T19:51:24.612911Z","iopub.status.idle":"2023-05-01T19:51:24.624822Z","shell.execute_reply.started":"2023-05-01T19:51:24.612877Z","shell.execute_reply":"2023-05-01T19:51:24.623693Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"CPU times: user 3.81 ms, sys: 2 ms, total: 5.81 ms\nWall time: 4 ms\n","output_type":"stream"},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 154036,  66896,  13600, 192765]])"},"metadata":{}}]},{"cell_type":"markdown","source":"Time taken is 6 ms, which is close to 6 times more than previous search. Let's take a look at the results.","metadata":{}},{"cell_type":"markdown","source":"First one is same, let's have a look at the second and third result for comparison.","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[154036].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:35.466948Z","iopub.execute_input":"2023-05-01T19:51:35.467682Z","iopub.status.idle":"2023-05-01T19:51:35.475573Z","shell.execute_reply.started":"2023-05-01T19:51:35.467642Z","shell.execute_reply":"2023-05-01T19:51:35.474361Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"'  The current leading paradigm for temporal information extraction from text\\nconsists of three phases: (1) recognition of events and temporal expressions,\\n(2) recognition of temporal relations among them, and (3) time-line\\nconstruction from the temporal relations. In contrast to the first two phases,\\nthe last phase, time-line construction, received little attention and is the\\nfocus of this work. In this paper, we propose a new method to construct a\\nlinear time-line from a set of (extracted) temporal relations. But more\\nimportantly, we propose a novel paradigm in which we directly predict start and\\nend-points for events from the text, constituting a time-line without going\\nthrough the intermediate step of prediction of temporal relations as in earlier\\nwork. Within this paradigm, we propose two models that predict in linear\\ncomplexity, and a new training loss using TimeML-style annotations, yielding\\npromising results.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"docs_df.iloc[66896].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:37.533402Z","iopub.execute_input":"2023-05-01T19:51:37.533785Z","iopub.status.idle":"2023-05-01T19:51:37.542161Z","shell.execute_reply.started":"2023-05-01T19:51:37.533751Z","shell.execute_reply":"2023-05-01T19:51:37.541137Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"'  It is commonly acknowledged that temporal expression extractors are important\\ncomponents of larger natural language processing systems like information\\nretrieval and question answering systems. Extraction and normalization of\\ntemporal expressions in Turkish has not been given attention so far except the\\nextraction of some date and time expressions within the course of named entity\\nrecognition. As TimeML is the current standard of temporal expression and event\\nannotation in natural language texts, in this paper, we present an analysis of\\ntemporal expressions in Turkish based on the related TimeML classification\\n(i.e., date, time, duration, and set expressions). We have created a lexicon\\nfor Turkish temporal expressions and devised considerably wide-coverage\\npatterns using the lexical classes as the building blocks. We believe that the\\nproposed patterns, together with convenient normalization rules, can be readily\\nused by prospective temporal expression extraction tools for Turkish.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"The match is better for the query as we increase the nprobe number but time increases. It's a tradeoff between performance and accuracy.","metadata":{}},{"cell_type":"markdown","source":"Let's see times for few more nprobe numbers","metadata":{}},{"cell_type":"code","source":"index.nprobe = 5","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:38.817491Z","iopub.execute_input":"2023-05-01T19:51:38.818506Z","iopub.status.idle":"2023-05-01T19:51:38.823770Z","shell.execute_reply.started":"2023-05-01T19:51:38.818447Z","shell.execute_reply":"2023-05-01T19:51:38.822536Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:39.315189Z","iopub.execute_input":"2023-05-01T19:51:39.315722Z","iopub.status.idle":"2023-05-01T19:51:39.326164Z","shell.execute_reply.started":"2023-05-01T19:51:39.315687Z","shell.execute_reply":"2023-05-01T19:51:39.324756Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"CPU times: user 3.36 ms, sys: 6 µs, total: 3.37 ms\nWall time: 2.29 ms\n","output_type":"stream"},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 154036,  66896,  13600, 192765]])"},"metadata":{}}]},{"cell_type":"code","source":"index.nprobe = 100","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:39.687996Z","iopub.execute_input":"2023-05-01T19:51:39.688584Z","iopub.status.idle":"2023-05-01T19:51:39.695262Z","shell.execute_reply.started":"2023-05-01T19:51:39.688553Z","shell.execute_reply":"2023-05-01T19:51:39.694282Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T19:51:41.796185Z","iopub.execute_input":"2023-05-01T19:51:41.796863Z","iopub.status.idle":"2023-05-01T19:51:41.840824Z","shell.execute_reply.started":"2023-05-01T19:51:41.796824Z","shell.execute_reply":"2023-05-01T19:51:41.839661Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"CPU times: user 37.8 ms, sys: 13 µs, total: 37.8 ms\nWall time: 36.5 ms\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 154036,  66896,  13600, 192765]])"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can clearly see, increasing the nprobe number increases the number of cells that needs to be searched for the result to be returned. This increases the accuracy as set of data that is searched increases, but takes more time. Proper nprobe number can be selected based on requirements, as the time required to search in millions of documents can be significantly higher than the milliseconds we are seeing here for half a million docs.\n\nFAISS also provides us with a lot of control compared to standar cosine_similarity that we used earlier with sentence-transformers.","metadata":{}},{"cell_type":"markdown","source":"Another optimization technique is Product Quantization (PQ). \n\nEarlier, where we reduced the search time by reducing the search area. This helps in reducing search time. But what if, the dataset itself is huge and storing the complete vectors become an issue.\n\nQuantization helps us reduce the size of vectors by approximating the similarity metric. It compresses the vectors that results in approximation of the similarity metric. Hence, it reduces the search time. It does this by following the steps - \n\n1. Split the original vector into sub-vectors.\n2. Each set of subvectors, a clustering operation is performed which creates multiple centroids for each sub-vector set.\n3. Then,in the original vector, each sub-vector is replaced by the ID of its nearest set-specific centroid.\n\nIndexIVFPQ is used.","metadata":{}},{"cell_type":"code","source":"m = 8  # number of centroid IDs or basically number of sub-vectors in each compressed vector.\nbits = 8 # size of each centroid\nnlist = 200 # number of cells\n\nquantizer = faiss.IndexFlatL2(dim) # same l2 dist flat index\nindex = faiss.IndexIVFPQ(quantizer, dim, nlist, m, bits) ","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:05:45.243755Z","iopub.execute_input":"2023-05-01T20:05:45.244551Z","iopub.status.idle":"2023-05-01T20:05:45.313688Z","shell.execute_reply.started":"2023-05-01T20:05:45.244509Z","shell.execute_reply":"2023-05-01T20:05:45.312453Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"index.is_trained","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:05:57.203044Z","iopub.execute_input":"2023-05-01T20:05:57.203617Z","iopub.status.idle":"2023-05-01T20:05:57.215402Z","shell.execute_reply.started":"2023-05-01T20:05:57.203532Z","shell.execute_reply":"2023-05-01T20:05:57.214038Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\nindex.train(abstract_embeddings_np)\nindex.is_trained","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:06:23.288983Z","iopub.execute_input":"2023-05-01T20:06:23.289612Z","iopub.status.idle":"2023-05-01T20:06:31.757150Z","shell.execute_reply.started":"2023-05-01T20:06:23.289573Z","shell.execute_reply":"2023-05-01T20:06:31.755962Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"CPU times: user 8.16 s, sys: 193 ms, total: 8.35 s\nWall time: 8.46 s\n","output_type":"stream"},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"index.add(abstract_embeddings_np)","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:06:34.564264Z","iopub.execute_input":"2023-05-01T20:06:34.564886Z","iopub.status.idle":"2023-05-01T20:06:43.685503Z","shell.execute_reply.started":"2023-05-01T20:06:34.564847Z","shell.execute_reply":"2023-05-01T20:06:43.684425Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"index.nprobe","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:07:05.782256Z","iopub.execute_input":"2023-05-01T20:07:05.782685Z","iopub.status.idle":"2023-05-01T20:07:05.791817Z","shell.execute_reply.started":"2023-05-01T20:07:05.782647Z","shell.execute_reply":"2023-05-01T20:07:05.790344Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:07:09.356844Z","iopub.execute_input":"2023-05-01T20:07:09.357674Z","iopub.status.idle":"2023-05-01T20:07:09.368074Z","shell.execute_reply.started":"2023-05-01T20:07:09.357631Z","shell.execute_reply":"2023-05-01T20:07:09.366626Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"CPU times: user 1.05 ms, sys: 1.02 ms, total: 2.07 ms\nWall time: 1.41 ms\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"array([[ 16069, 245940, 368076, 273379, 483819]])"},"metadata":{}}]},{"cell_type":"code","source":"index.nprobe = 10","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:18:40.600932Z","iopub.execute_input":"2023-05-01T20:18:40.601960Z","iopub.status.idle":"2023-05-01T20:18:40.607605Z","shell.execute_reply.started":"2023-05-01T20:18:40.601921Z","shell.execute_reply":"2023-05-01T20:18:40.606349Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndist, top_k = index.search(query_embedding_np, 5)  # search\ntop_k","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:18:41.706388Z","iopub.execute_input":"2023-05-01T20:18:41.706907Z","iopub.status.idle":"2023-05-01T20:18:41.722829Z","shell.execute_reply.started":"2023-05-01T20:18:41.706859Z","shell.execute_reply":"2023-05-01T20:18:41.720670Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"CPU times: user 1.57 ms, sys: 1.01 ms, total: 2.59 ms\nWall time: 2.02 ms\n","output_type":"stream"},{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"array([[ 16069,  13597, 192765,  66896, 204477]])"},"metadata":{}}]},{"cell_type":"markdown","source":"We have further reduced the search time for nprob=10 from 6ms to 2ms. Let's see the search results.","metadata":{}},{"cell_type":"code","source":"docs_df.iloc[13597].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:29:11.526611Z","iopub.execute_input":"2023-05-01T20:29:11.527164Z","iopub.status.idle":"2023-05-01T20:29:11.540667Z","shell.execute_reply.started":"2023-05-01T20:29:11.527061Z","shell.execute_reply":"2023-05-01T20:29:11.539036Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"'  Automatic temporal ordering of events described in discourse has been of\\ngreat interest in recent years. Event orderings are conveyed in text via va\\nrious linguistic mechanisms including the use of expressions such as \"before\",\\n\"after\" or \"during\" that explicitly assert a temporal relation -- temporal\\nsignals. In this paper, we investigate the role of temporal signals in temporal\\nrelation extraction and provide a quantitative analysis of these expres sions\\nin the TimeBank annotated corpus.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"docs_df.iloc[192765].abstract","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:29:30.821177Z","iopub.execute_input":"2023-05-01T20:29:30.821677Z","iopub.status.idle":"2023-05-01T20:29:30.831404Z","shell.execute_reply.started":"2023-05-01T20:29:30.821630Z","shell.execute_reply":"2023-05-01T20:29:30.830190Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"'  Automatic extraction of temporal information in text is an important\\ncomponent of natural language understanding. It involves two basic tasks: (1)\\nUnderstanding time expressions that are mentioned explicitly in text (e.g.,\\nFebruary 27, 1998 or tomorrow), and (2) Understanding temporal information that\\nis conveyed implicitly via relations. In this paper, we introduce CogCompTime,\\na system that has these two important functionalities. It incorporates the most\\nrecent progress, achieves state-of-the-art performance, and is publicly\\navailable.1 We believe that this demo will be useful for multiple time-aware\\napplications and provide valuable insight for future research in temporal\\nunderstanding.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see that the ordering of results has changes from our previous output even though the set of documents overlap. This is because of the approximation of the similarity metric.","metadata":{}},{"cell_type":"code","source":"index.make_direct_map()","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:20:30.747684Z","iopub.execute_input":"2023-05-01T20:20:30.748617Z","iopub.status.idle":"2023-05-01T20:20:30.757634Z","shell.execute_reply.started":"2023-05-01T20:20:30.748565Z","shell.execute_reply":"2023-05-01T20:20:30.756516Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"index.reconstruct(16069).shape","metadata":{"execution":{"iopub.status.busy":"2023-05-01T20:20:36.922431Z","iopub.execute_input":"2023-05-01T20:20:36.922909Z","iopub.status.idle":"2023-05-01T20:20:36.931680Z","shell.execute_reply.started":"2023-05-01T20:20:36.922863Z","shell.execute_reply":"2023-05-01T20:20:36.930512Z"},"trusted":true},"execution_count":120,"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"(384,)"},"metadata":{}}]},{"cell_type":"markdown","source":"Referenced from - [FAISS exploration](https://www.pinecone.io/learn/faiss-tutorial/)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}